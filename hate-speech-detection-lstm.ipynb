{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hate-speech-detection-lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s4A--cNtElw"
      },
      "source": [
        "#import required libraries\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import gzip\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbIYrV6ltSZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1235a5e-df1e-4acd-c0a4-ee008be6d4f2"
      },
      "source": [
        "#mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlsMaCjytQsV",
        "outputId": "4a1a58fb-030d-45f4-b2ea-5eecaa79b357"
      },
      "source": [
        "#install fasttext\n",
        "! pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3093765 sha256=e6195c0609b0889c82e32c6dc799a059bb7e564aaa492df0e1e1d977d524ebd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94nUwEMEt43i",
        "outputId": "0aa68979-afc9-4972-f39a-da152e5128ab"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.vec.gz\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 16:26:57--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 481477801 (459M) [binary/octet-stream]\n",
            "Saving to: ‘cc.si.300.vec.gz’\n",
            "\n",
            "cc.si.300.vec.gz    100%[===================>] 459.17M  31.9MB/s    in 15s     \n",
            "\n",
            "2021-06-08 16:27:12 (30.8 MB/s) - ‘cc.si.300.vec.gz’ saved [481477801/481477801]\n",
            "\n",
            "--2021-06-08 16:27:12--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3181346570 (3.0G) [application/octet-stream]\n",
            "Saving to: ‘cc.si.300.bin.gz’\n",
            "\n",
            "cc.si.300.bin.gz     14%[=>                  ] 432.59M  32.8MB/s    eta 87s    ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvhyXkCvt_T7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585780a8-7978-4193-fc8a-ea2be9634626"
      },
      "source": [
        "!gzip -d cc.si.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: cc.si.300.bin.gz: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Roko__txp4iy",
        "outputId": "9ef8ebf6-52af-4071-e964-763e1e9078cc"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText\n",
        "!sudo python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3854, done.\u001b[K\n",
            "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3854/3854), 8.22 MiB | 28.94 MiB/s, done.\n",
            "Resolving deltas: 100% (2417/2417), done.\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yfLjVsh39Br",
        "outputId": "a3f7150c-6996-4049-8107-30900c3e8995"
      },
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "ft = fasttext.load_model('/content/cc.si.300.bin')\n",
        "ft.get_dimension()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh_hhoPnqmtM",
        "outputId": "a8f6e08f-7703-42f0-a414-c6d767222bfd"
      },
      "source": [
        "import fasttext.util\n",
        "fasttext.util.reduce_model(ft, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT30FgHIuD6P",
        "outputId": "c7342ec7-8e46-48ee-f6f3-5f580975a394"
      },
      "source": [
        "#reading the dataset\n",
        "dataset = []\n",
        "with open(\"/content/drive/MyDrive/sinhala-hate-speech-dataset.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "      label = row[2]\n",
        "      post = row[1]\n",
        "      item = []\n",
        "      item.append(post)\n",
        "      if label == '0':\n",
        "        item.append(0)\n",
        "      elif label == '1':\n",
        "        item.append(1)\n",
        "      else:\n",
        "        print('ERROR') \n",
        "        continue  \n",
        "      dataset.append(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWRKIDkKu-Cy",
        "outputId": "1cae78b0-824d-4431-8c95-62b7b9400fcb"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE6zeNiyvBlP"
      },
      "source": [
        "#separate posts and labels\n",
        "posts=[]\n",
        "labels=[]\n",
        "for x in range(len(dataset)):\n",
        "    posts.append(dataset[x][0])\n",
        "    labels.append(dataset[x][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ScGrbiq-Sik"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "posts_train, posts_test, labels_train, labels_test = train_test_split(np.asarray(posts), np.asarray(labels), test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTQAaXCzzvM-"
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 100\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(posts_train)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(posts_train)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(posts_test)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8qxCo_-3CWA"
      },
      "source": [
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = ft.get_word_vector(word)\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAFxRkiX3u3X"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, dropout=0.5)),\n",
        "    tf.keras.layers.Dense(24, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNTv_3fz41i4",
        "outputId": "96c1229f-63b8-4ea3-a2ad-3a12527c2ffc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 120, 100)          1760000   \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 64)                34048     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 24)                1560      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 1,795,633\n",
            "Trainable params: 35,633\n",
            "Non-trainable params: 1,760,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hxURXrVvkCE"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGWK602m44e4",
        "outputId": "0c37da64-65c3-4ecc-8651-c1fb765d0f87"
      },
      "source": [
        "num_epochs=100\n",
        "history = model.fit(padded, labels_train, epochs=num_epochs, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "179/179 [==============================] - 18s 80ms/step - loss: 0.6259 - accuracy: 0.7118\n",
            "Epoch 2/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.6967 - accuracy: 0.5347\n",
            "Epoch 3/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.5390 - accuracy: 0.7306\n",
            "Epoch 4/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.4445 - accuracy: 0.8091\n",
            "Epoch 5/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.4315 - accuracy: 0.8132\n",
            "Epoch 6/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.4200 - accuracy: 0.8169\n",
            "Epoch 7/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3930 - accuracy: 0.8271\n",
            "Epoch 8/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3889 - accuracy: 0.8241\n",
            "Epoch 9/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3629 - accuracy: 0.8374\n",
            "Epoch 10/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3600 - accuracy: 0.8452\n",
            "Epoch 11/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3638 - accuracy: 0.8379\n",
            "Epoch 12/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3976 - accuracy: 0.8196\n",
            "Epoch 13/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.4133 - accuracy: 0.8147\n",
            "Epoch 14/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3776 - accuracy: 0.8307\n",
            "Epoch 15/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3712 - accuracy: 0.8292\n",
            "Epoch 16/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3433 - accuracy: 0.8532\n",
            "Epoch 17/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3749 - accuracy: 0.8384\n",
            "Epoch 18/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3671 - accuracy: 0.8396\n",
            "Epoch 19/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.4466 - accuracy: 0.7897\n",
            "Epoch 20/100\n",
            "179/179 [==============================] - 15s 81ms/step - loss: 0.3948 - accuracy: 0.8295\n",
            "Epoch 21/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3604 - accuracy: 0.8355\n",
            "Epoch 22/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3426 - accuracy: 0.8444\n",
            "Epoch 23/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.3413 - accuracy: 0.8465\n",
            "Epoch 24/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3182 - accuracy: 0.8590\n",
            "Epoch 25/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3474 - accuracy: 0.8472\n",
            "Epoch 26/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3290 - accuracy: 0.8577\n",
            "Epoch 27/100\n",
            "179/179 [==============================] - 15s 81ms/step - loss: 0.3169 - accuracy: 0.8680\n",
            "Epoch 28/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3159 - accuracy: 0.8669\n",
            "Epoch 29/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3142 - accuracy: 0.8609\n",
            "Epoch 30/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3150 - accuracy: 0.8610\n",
            "Epoch 31/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3646 - accuracy: 0.8340\n",
            "Epoch 32/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.4132 - accuracy: 0.8097\n",
            "Epoch 33/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3812 - accuracy: 0.8321\n",
            "Epoch 34/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.4117 - accuracy: 0.8166\n",
            "Epoch 35/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3414 - accuracy: 0.8570\n",
            "Epoch 36/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3474 - accuracy: 0.8465\n",
            "Epoch 37/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3372 - accuracy: 0.8484\n",
            "Epoch 38/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3968 - accuracy: 0.8210\n",
            "Epoch 39/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3725 - accuracy: 0.8325\n",
            "Epoch 40/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3332 - accuracy: 0.8550\n",
            "Epoch 41/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3355 - accuracy: 0.8517\n",
            "Epoch 42/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3241 - accuracy: 0.8586\n",
            "Epoch 43/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3191 - accuracy: 0.8593\n",
            "Epoch 44/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3124 - accuracy: 0.8679\n",
            "Epoch 45/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3178 - accuracy: 0.8602\n",
            "Epoch 46/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3479 - accuracy: 0.8455\n",
            "Epoch 47/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3265 - accuracy: 0.8582\n",
            "Epoch 48/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3248 - accuracy: 0.8565\n",
            "Epoch 49/100\n",
            "179/179 [==============================] - 15s 81ms/step - loss: 0.3104 - accuracy: 0.8621\n",
            "Epoch 50/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3114 - accuracy: 0.8588\n",
            "Epoch 51/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.3429 - accuracy: 0.8451\n",
            "Epoch 52/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2999 - accuracy: 0.8620\n",
            "Epoch 53/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3056 - accuracy: 0.8671\n",
            "Epoch 54/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2939 - accuracy: 0.8721\n",
            "Epoch 55/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2791 - accuracy: 0.8720\n",
            "Epoch 56/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2905 - accuracy: 0.8677\n",
            "Epoch 57/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3003 - accuracy: 0.8680\n",
            "Epoch 58/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2929 - accuracy: 0.8715\n",
            "Epoch 59/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2803 - accuracy: 0.8845\n",
            "Epoch 60/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2824 - accuracy: 0.8779\n",
            "Epoch 61/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2868 - accuracy: 0.8766\n",
            "Epoch 62/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2850 - accuracy: 0.8786\n",
            "Epoch 63/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2903 - accuracy: 0.8762\n",
            "Epoch 64/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2725 - accuracy: 0.8848\n",
            "Epoch 65/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2650 - accuracy: 0.8845\n",
            "Epoch 66/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.3347 - accuracy: 0.8461\n",
            "Epoch 67/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3515 - accuracy: 0.8399\n",
            "Epoch 68/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2816 - accuracy: 0.8773\n",
            "Epoch 69/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2877 - accuracy: 0.8783\n",
            "Epoch 70/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2805 - accuracy: 0.8818\n",
            "Epoch 71/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2551 - accuracy: 0.8948\n",
            "Epoch 72/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2514 - accuracy: 0.8936\n",
            "Epoch 73/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2745 - accuracy: 0.8785\n",
            "Epoch 74/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2750 - accuracy: 0.8797\n",
            "Epoch 75/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2696 - accuracy: 0.8842\n",
            "Epoch 76/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2664 - accuracy: 0.8928\n",
            "Epoch 77/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2653 - accuracy: 0.8885\n",
            "Epoch 78/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2705 - accuracy: 0.8856\n",
            "Epoch 79/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3132 - accuracy: 0.8661\n",
            "Epoch 80/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2646 - accuracy: 0.8862\n",
            "Epoch 81/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2626 - accuracy: 0.8890\n",
            "Epoch 82/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2612 - accuracy: 0.8952\n",
            "Epoch 83/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2467 - accuracy: 0.8960\n",
            "Epoch 84/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2540 - accuracy: 0.8945\n",
            "Epoch 85/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2593 - accuracy: 0.8888\n",
            "Epoch 86/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2511 - accuracy: 0.8933\n",
            "Epoch 87/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2485 - accuracy: 0.8918\n",
            "Epoch 88/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2394 - accuracy: 0.8996\n",
            "Epoch 89/100\n",
            "179/179 [==============================] - 15s 85ms/step - loss: 0.2396 - accuracy: 0.8996\n",
            "Epoch 90/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2366 - accuracy: 0.9024\n",
            "Epoch 91/100\n",
            "179/179 [==============================] - 15s 86ms/step - loss: 0.2533 - accuracy: 0.8935\n",
            "Epoch 92/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.3780 - accuracy: 0.8347\n",
            "Epoch 93/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2921 - accuracy: 0.8815\n",
            "Epoch 94/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2535 - accuracy: 0.8937\n",
            "Epoch 95/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2696 - accuracy: 0.8839\n",
            "Epoch 96/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2572 - accuracy: 0.8927\n",
            "Epoch 97/100\n",
            "179/179 [==============================] - 15s 82ms/step - loss: 0.2632 - accuracy: 0.8903\n",
            "Epoch 98/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2695 - accuracy: 0.8837\n",
            "Epoch 99/100\n",
            "179/179 [==============================] - 15s 83ms/step - loss: 0.2484 - accuracy: 0.8938\n",
            "Epoch 100/100\n",
            "179/179 [==============================] - 15s 84ms/step - loss: 0.2418 - accuracy: 0.8956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j1SHcx-E0r7",
        "outputId": "e88d7f8c-ef60-444e-eedb-8451c40e5143"
      },
      "source": [
        "  model.evaluate(testing_padded, labels_test, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 0.3360 - accuracy: 0.8677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33602118492126465, 0.8677165508270264]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}